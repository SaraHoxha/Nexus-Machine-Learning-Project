# Team Nexus

# Sources

## Basic Models

* **GeeksforGeeks.** (2023, December 14). How to find the optimal value of K in KNN. [Link](https://www.geeksforgeeks.org/how-to-find-the-optimal-value-of-k-in-knn/)

* **Koehrsen, W.** (2020, August 18). Random Forest Simple Explanation. Medium. [Link](https://williamkoehrsen.medium.com/random-forest-simple-explanation-377895a60d2d)

* **Shafi, A.** (2023, February 24). Random Forest classification with Scikit-Learn. DataCamp. [Link](https://www.datacamp.com/tutorial/random-forests-classifier-python)

* **Saini, A.** (2024, January 5). A beginner’s guide to logistic regression. Analytics Vidhya. [Link](https://www.analyticsvidhya.com/blog/2021/08/conceptual-understanding-of-logistic-regression-for-data-science-beginners/)

* **del cuento, M.** (2020, September 13). Kernel ridge regression – python tutorial - marcos del cueto. Marcos del Cueto - Theoretical Chemist, PhD. [Link](https://www.mdelcueto.com/blog/kernel-ridge-regression-tutorial/)

* **JobLib.** (2021). Persistence¶. Persistence - joblib 1.4.dev0 documentation. [Link](https://joblib.readthedocs.io/en/latest/persistence.html)

* **Pandas.** (2024). Pandas documentation#. pandas documentation - pandas 2.2.0 documentation. [Link](https://pandas.pydata.org/docs/)

* **scikit team.** (2024). Learn. scikit. [Link](https://scikit-learn.org/stable/)

* **Matplotlib team.** (2024). Matplotlib 3.8.2 documentation#. Matplotlib documentation - Matplotlib 3.8.2 documentation. [Link](https://matplotlib.org/stable/index.html)

* **python team.** (2024). Math - mathematical functions. Python documentation. [Link](https://docs.python.org/3/library/math.html)

* **TensorFlow.** (2024). API documentation : tensorflow V2.15.0.POST1. [Link](https://www.tensorflow.org/api_docs)

## Neural Networks

* **Kim, H.** (2022, July 3). Hyperparameter tuning with Keras-tuner full tutorial. Medium. [Link](https://haneulkim.medium.com/hyperparameter-tuning-with-keras-tuner-full-tutorial-f8128397e857)

* **shaktiwadekar9.** (2020). Shaktiwadekar9/Kerastuner-TF2: Kerastuner in tensorflow 2. GitHub. [Link](https://github.com/shaktiwadekar9/KerasTuner-TF2/tree/main)

* **TensorFlow.** (2024). Writing a training loop from scratch : Tensorflow Core. [Link](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch)

* **Team, K.** (2024). Keras Documentation: The Tuner classes in Kerastuner. [Link](https://keras.io/api/keras_tuner/tuners/)

* **Brownlee, J.** (2022, August 5). Dropout regularization in deep learning models with Keras. MachineLearningMastery.com. [Link](https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/#:~:text=Dropout%20is%20easily%20implemented%20by,the%20skill%20of%20the%20model)

* **Jose, G. V.** (2019, October 3). Useful plots to diagnose your neural network. Medium. [Link](https://towardsdatascience.com/useful-plots-to-diagnose-your-neural-network-521907fa2f45)

* **Team, K.** (2024b). Keras Documentation: The Tuner classes in Kerastuner. [Link](https://keras.io/api/keras_tuner/tuners/)

* **Brownlee, J.** (2019, August 6). How to configure the number of layers and nodes in a neural network. MachineLearningMastery.com. [Link](https://machinelearningmastery.com/how-to-configure-the-number-of-layers-and-nodes-in-a-neural-network/)

* **Quora.** (2020). Data splits. [Link](https://www.quora.com/In-a-dataset-consisting-of-1-000-samples-it-has-been-shown-that-a-70-30-split-will-provide-a-good-estimation-of-the-test-accuracy-of-the-trained-models-If-the-dataset-size-increases-to-10-000-samples-what-split)

* **Gholamy, A., Kreinovich, V., & Kosheleva, O.** (2018). Why 70/30 or 80/20 relation between training and testing sets: A pedagogical explanation. ScholarWorks@UTEP. [Link](https://scholarworks.utep.edu/cs_techrep/1209/)

* **Hastie, T., Tibshirani, R., & Friedman, J.** (2017). The Elements of Statistical Learning Data Mining, Inference, and Prediction. [Link](https://hastie.su.domains/Papers/ESLII.pdf)
