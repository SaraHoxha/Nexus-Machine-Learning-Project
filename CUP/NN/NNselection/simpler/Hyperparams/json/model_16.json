{"activation": "tanh", "activation2": "leaky_relu", "activation3": "linear", "optimizer": "adam", "learning rate": 0.005199639864526093, "momentum": 0.7566992082199369, "weight decay": 0.5024324398513328, "rho": 0.26263714048528475, "epsilon": 0.973945257889811, "initial accumulator": 0.5198628524131284, "0_units": 46, "n_layers": 1, "n_layers2_": 2, "0_1_units": 3, "dropout": false, "0_2_units": 7, "dropout rate2": 0.15, "dropout rate": 0.1}