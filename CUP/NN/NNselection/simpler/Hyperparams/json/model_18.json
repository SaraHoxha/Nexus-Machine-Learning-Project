{"activation": "leaky_relu", "activation2": "linear", "activation3": "linear", "optimizer": "adam", "learning rate": 0.009388975962722408, "momentum": 0.969966243152585, "weight decay": 0.7636756705767299, "rho": 0.3998304285831376, "epsilon": 0.3734161867565493, "initial accumulator": 0.4049459439952007, "0_units": 38, "n_layers": 2, "n_layers2_": 0, "0_1_units": 43, "dropout": true, "0_2_units": 50, "dropout rate2": 0.2, "dropout rate": 0.2}