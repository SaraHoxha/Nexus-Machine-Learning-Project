{"activation": "tanh", "activation2": "leaky_relu", "activation3": "sigmoid", "optimizer": "SGD", "learning rate": 0.008418556739685288, "momentum": 0.8805280552538537, "weight decay": 0.02765161143420322, "rho": 0.8571418735129414, "epsilon": 0.05850245841978008, "initial accumulator": 0.18663497858174105, "0_units": 37, "n_layers": 1, "n_layers2_": 0, "0_1_units": 43, "dropout": true, "0_2_units": 40, "dropout rate2": 0.2, "dropout rate": 0.2}