{"activation": "tanh", "activation2": "leaky_relu", "activation3": "linear", "optimizer": "adam", "learning rate": 0.009844749431262557, "momentum": 0.20561914306734436, "weight decay": 0.5896433617266378, "rho": 0.6678884633223058, "epsilon": 0.18853047833753508, "initial accumulator": 0.2830580986628089, "0_units": 47, "n_layers": 0, "n_layers2_": 0, "0_1_units": 32, "dropout": true, "0_2_units": 28, "dropout rate2": 0.2, "dropout rate": 0.2}