{"activation": "tanh", "activation2": "leaky_relu", "activation3": "leaky_relu", "optimizer": "adam", "learning rate": 0.00952458130075342, "momentum": 0.8130407311283601, "weight decay": 0.7759398092139389, "rho": 0.12421875485876263, "epsilon": 0.2099636597097645, "initial accumulator": 0.27830760737424254, "0_units": 49, "n_layers": 1, "n_layers2_": 1, "0_1_units": 5, "dropout": true, "0_2_units": 47, "dropout rate2": 0.1, "dropout rate": 0.15}